{"cells":[{"cell_type":"markdown","metadata":{"id":"bdtwG8K3YONr"},"source":["# M5 Forecast: Poisson loss (top 10%)\n","\n","This very simple script was lucky enough to get top 10% in private lb. \n","\n","I moved the time horizon of the previous version of this notebook by 28 days and removed all \"magic\" stuff. The winning solutions did clearly better in terms of performance, but simplicity is worth a lot when it comes to maintainance etc."]},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fi6Ij7ghkR6h","executionInfo":{"status":"ok","timestamp":1679308272823,"user_tz":-480,"elapsed":68947,"user":{"displayName":"TYJ","userId":"09404405429252445579"}},"outputId":"5b2b6cca-c48d-4bb6-8b04-a8642be07543"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Colab_Notebooks/kaggle/\n","# !pip install -r ./m5-forecasting/requirements.txt\n","!pip install polars -q\n","!git config --global user.email \"yoggibear6@gmail.com\"\n","!git config --global user.name \"yjtek\"\n","!git checkout -f main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h9wU0sk6YQKT","executionInfo":{"status":"ok","timestamp":1679308487350,"user_tz":-480,"elapsed":8251,"user":{"displayName":"TYJ","userId":"09404405429252445579"}},"outputId":"233eaeaf-d435-4de4-de8d-a10d17b15cb7"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab_Notebooks/kaggle\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.2/16.2 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","Updating files: 100% (10/10), done.\n","Already on 'main'\n","Your branch is up to date with 'origin/main'.\n"]}]},{"cell_type":"code","source":["# !git pull && git add . && git commit -m \"push colab changes\" && git push origin main"],"metadata":{"id":"-BlrKM8PZl99","executionInfo":{"status":"ok","timestamp":1679306964688,"user_tz":-480,"elapsed":407,"user":{"displayName":"TYJ","userId":"09404405429252445579"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"id":"QFZQyUxdYONu","executionInfo":{"status":"ok","timestamp":1679306973070,"user_tz":-480,"elapsed":2238,"user":{"displayName":"TYJ","userId":"09404405429252445579"}}},"outputs":[],"source":["import pandas as pd\n","import polars as pl\n","import numpy as np\n","import os\n","import lightgbm as lgb\n","\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lbw7jD7qYONv","executionInfo":{"status":"ok","timestamp":1679306975121,"user_tz":-480,"elapsed":4,"user":{"displayName":"TYJ","userId":"09404405429252445579"}},"outputId":"d1c38604-c85a-45d9-a6f9-70d973a8c8fe"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["polars.config.Config"]},"metadata":{},"execution_count":10}],"source":["pl.Config.set_tbl_rows(999)\n","pl.Config.set_tbl_width_chars(999)\n","pl.Config.set_fmt_str_lengths(999) "]},{"cell_type":"markdown","metadata":{"id":"kJnuj7K-YONw"},"source":["## Load data"]},{"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp /content/drive/MyDrive/Colab_Notebooks/kaggle.json ~/.kaggle/ \n","!chmod 600 ~/.kaggle/kaggle.json\n","!bash ./m5-forecasting/getfiles.sh"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cin3xWpCfv9a","executionInfo":{"status":"ok","timestamp":1679308829516,"user_tz":-480,"elapsed":39393,"user":{"displayName":"TYJ","userId":"09404405429252445579"}},"outputId":"9e32c3b4-3497-4a44-b8e2-a9013eb4abda"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["m5-forecasting-accuracy.zip: Skipping, found more recently modified local copy (use --force to force download)\n","m5-forecasting-uncertainty.zip: Skipping, found more recently modified local copy (use --force to force download)\n","Archive:  ./m5-forecasting/data/m5-forecasting-accuracy.zip\n","  inflating: ./m5-forecasting/data/calendar.csv  \n","  inflating: ./m5-forecasting/data/sales_train_evaluation.csv  \n","  inflating: ./m5-forecasting/data/sales_train_validation.csv  \n","  inflating: ./m5-forecasting/data/sample_submission.csv  \n","  inflating: ./m5-forecasting/data/sell_prices.csv  \n","Archive:  ./m5-forecasting/data/m5-forecasting-uncertainty.zip\n","replace ./m5-forecasting/data/calendar.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n","  inflating: ./m5-forecasting/data/calendar.csv  \n","  inflating: ./m5-forecasting/data/sales_train_evaluation.csv  \n","  inflating: ./m5-forecasting/data/sales_train_validation.csv  \n","  inflating: ./m5-forecasting/data/sample_submission.csv  \n","  inflating: ./m5-forecasting/data/sell_prices.csv  \n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uzrvs1qTYONw"},"outputs":[],"source":["path = \"../data\"\n","calendar = pl.read_csv(os.path.join(path, \"calendar.csv\"))\n","selling_prices = pl.read_csv(os.path.join(path, \"sell_prices.csv\"))\n","sample_submission_accuracy = pl.read_csv(os.path.join(path, \"sample_submission_accuracy.csv\"))\n","sales = pl.read_csv(os.path.join(path, \"sales_train_evaluation.csv\"))"]},{"cell_type":"markdown","metadata":{"id":"h_RgWkBtYONw"},"source":["## Prepare Calendar"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JsU-dcxvYONw","outputId":"14f6325b-96f9-4123-b219-957b0737570c"},"outputs":[{"data":{"text/html":["<div><style>\n",".dataframe > thead > tr > th,\n",".dataframe > tbody > tr > td {\n","  text-align: right;\n","}\n","</style>\n","<small>shape: (5, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>wm_yr_wk</th><th>wday</th><th>month</th><th>year</th><th>d</th><th>event_name_1</th><th>event_name_2</th><th>snap_CA</th><th>snap_TX</th><th>snap_WI</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>11101</td><td>1</td><td>1</td><td>2011</td><td>1</td><td>31.0</td><td>5.0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>11101</td><td>2</td><td>1</td><td>2011</td><td>2</td><td>31.0</td><td>5.0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>11101</td><td>3</td><td>1</td><td>2011</td><td>3</td><td>31.0</td><td>5.0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>11101</td><td>4</td><td>2</td><td>2011</td><td>4</td><td>31.0</td><td>5.0</td><td>1</td><td>1</td><td>0</td></tr><tr><td>11101</td><td>5</td><td>2</td><td>2011</td><td>5</td><td>31.0</td><td>5.0</td><td>1</td><td>0</td><td>1</td></tr></tbody></table></div>"],"text/plain":["shape: (5, 10)\n","┌──────────┬──────┬───────┬──────┬───┬──────────────┬─────────┬─────────┬─────────┐\n","│ wm_yr_wk ┆ wday ┆ month ┆ year ┆ … ┆ event_name_2 ┆ snap_CA ┆ snap_TX ┆ snap_WI │\n","│ ---      ┆ ---  ┆ ---   ┆ ---  ┆   ┆ ---          ┆ ---     ┆ ---     ┆ ---     │\n","│ i64      ┆ i64  ┆ i64   ┆ i64  ┆   ┆ f64          ┆ i64     ┆ i64     ┆ i64     │\n","╞══════════╪══════╪═══════╪══════╪═══╪══════════════╪═════════╪═════════╪═════════╡\n","│ 11101    ┆ 1    ┆ 1     ┆ 2011 ┆ … ┆ 5.0          ┆ 0       ┆ 0       ┆ 0       │\n","│ 11101    ┆ 2    ┆ 1     ┆ 2011 ┆ … ┆ 5.0          ┆ 0       ┆ 0       ┆ 0       │\n","│ 11101    ┆ 3    ┆ 1     ┆ 2011 ┆ … ┆ 5.0          ┆ 0       ┆ 0       ┆ 0       │\n","│ 11101    ┆ 4    ┆ 2     ┆ 2011 ┆ … ┆ 5.0          ┆ 1       ┆ 1       ┆ 0       │\n","│ 11101    ┆ 5    ┆ 2     ┆ 2011 ┆ … ┆ 5.0          ┆ 1       ┆ 0       ┆ 1       │\n","└──────────┴──────┴───────┴──────┴───┴──────────────┴─────────┴─────────┴─────────┘"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["def prep_calendar(df):\n","    featnames = [\"event_name_1\", \"event_name_2\"]\n","    ord_enc = OrdinalEncoder()\n","    featvals = ord_enc.fit_transform(calendar.select(featnames).to_numpy()) + 1\n","\n","    df2 = (\n","        df\n","        .drop(\"date\", \"weekday\", \"event_type_1\", \"event_type_2\")\n","        .with_columns(\n","            pl.col('d').str.replace('d_', '').cast(pl.Int64).alias('d')\n","        )\n","        .pipe(\n","            lambda df: (\n","                df.with_columns([\n","                    pl.Series(name=f'{featname}', values=featval) for featname, featval in zip(featnames, featvals.T)\n","                ])\n","            )\n","        )\n","        # .pipe(\n","        #     lambda df: (\n","        #         df.select(\n","        #             [pl.col(int8col).cast(pl.Int8).alias(int8col) for int8col in \n","        #              [\"wday\", \"month\",  \"snap_CA\", \"snap_TX\", \"snap_WI\"] + featnames] +\n","        #              [pl.col(int16col).cast(pl.Int16).alias(int16col) for int16col in\n","        #               ['wm_yr_wk', 'year', 'd']]\n","        #         )\n","        #     )\n","        # )\n","        .select('wm_yr_wk', 'wday', 'month', 'year', 'd', 'event_name_1', 'event_name_2', 'snap_CA', 'snap_TX', 'snap_WI')\n","    )\n","\n","    return df2\n","\n","calendar_final = prep_calendar(calendar)\n","calendar_final.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cibeMJS8YONx"},"outputs":[],"source":["# selling_prices.head().dtypes #.with_columns(pl.col('item_id').cast(pl.))"]},{"cell_type":"markdown","metadata":{"id":"TMOjDQWKYONx"},"source":["## Helper functions\n","\n","We need the following functions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ldz4IMZxYONx"},"outputs":[],"source":["LAGS = [7, 28]\n","WINDOWS = [7, 28]\n","FIRST = 1942 # first to predict\n","LENGTH = 28\n","DROP = 1000\n","\n","def make_demand_features(df: pl.DataFrame):\n","    \"\"\" Derive features from sales data and remove rows with missing values \"\"\"\n","    df2 = (\n","        df\n","        .with_columns(pl.col('demand').shift(1).over('id').cast(pl.Float32).alias(f'demand_lag1'))        \n","        .with_columns(*[\n","            pl.col('demand_lag1').shift(lag).over('id').cast(pl.Float32).alias(f'lag_t{lag}')\n","            for lag in LAGS\n","        ])\n","        .with_columns(*[\n","            pl.col(f'lag_t{lag}').rolling_mean(window_size=window).over('id').cast(pl.Float32).alias(f'rolling_mean_lag{lag}_window{window}')\n","            for lag in LAGS\n","            for window in WINDOWS\n","        ])\n","        .filter(pl.col(f'rolling_mean_lag{max(LAGS)}_window{max(WINDOWS)}').is_not_null())\n","    )\n","    return df2\n","\n","def drop_data_beyond_xdays(df: pl.DataFrame, x: int):\n","    df2 = (\n","        df\n","        .drop([f'd_{col+1}' for col in range(x)])\n","    )\n","    return df2\n","\n","def clean_id_string(df:pl.DataFrame):\n","    df2 = (\n","        df\n","        .with_columns(pl.col('id').str.replace('_evaluation', ''))\n","    )\n","    return df2\n","\n","def add_evaluation_days(df: pl.DataFrame, first_eval_day: int, length_eval_window: int):\n","    df2 = (\n","        df\n","        .select(*['*'] + [pl.lit(None).alias(f'd_{first_eval_day + x}') for x in range(length_eval_window)])\n","    )\n","    return df2\n","\n","def pivot_wide_to_long(df: pl.DataFrame):\n","    df2 = (\n","        df\n","        .melt(id_vars=['id', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id'], variable_name='d', value_name='demand')\n","        .with_columns(pl.col('d').str.replace('d_', '').cast(pl.Int64), pl.col('demand').cast(pl.Float32))\n","    )\n","    return df2\n","\n","def add_ordinal_encoding(df: pl.DataFrame, cols: list[str]) -> pl.DataFrame:\n","    # for col in cols:\n","    ord_enc = OrdinalEncoder()\n","    rawvals = df.select(cols).to_numpy()\n","    featvals = ord_enc.fit_transform(rawvals).T\n","    df2 = df.with_columns(*[pl.Series(name=col, values=val) for col, val in zip(cols, featvals)])\n","    return df2\n","\n","def split_train_valid_test(df: pl.DataFrame, first_eval_day: int, lags: list[int], windows: list[int]):\n","    test = (\n","        df.filter(pl.col('d') >= first_eval_day - max(lags) - max(windows) - 28)\n","    )\n","    trainval = (\n","        df.filter(pl.col('d') < first_eval_day)\n","    )\n","\n","    xfeats = [x for x in trainval.columns if x not in ['id', 'd', 'demand']]\n","\n","    xtrain, xval, ytrain, yval = train_test_split(trainval.drop(['id', 'd', 'demand']), trainval['demand'].to_numpy(), test_size=0.3, random_state=123)\n","    #train = lgb.Dataset(xtrain, label = ytrain)\n","    #valid = lgb.Dataset(xval, label = yval)\n","    return xtrain, xval, ytrain, yval, test, xfeats\n","\n","def prep_data(df, first_eval_day: int, length_eval_window: int, drop_days: int, lags: list[int], windows: list[int]):\n","    \"\"\" Prepare model data sets \"\"\"\n","    df = (\n","        sales\n","        .pipe(lambda df: drop_data_beyond_xdays(df, drop_days))\n","        .pipe(lambda df: clean_id_string(df))\n","        .pipe(lambda df: add_evaluation_days(df, first_eval_day=first_eval_day, length_eval_window=length_eval_window))\n","        .pipe(lambda df: pivot_wide_to_long(df))\n","        .pipe(lambda df: make_demand_features(df))\n","        \n","        .join(calendar_final, how='left', on='d')\n","        .join(selling_prices, how='left', on=[\"store_id\", \"item_id\", \"wm_yr_wk\"])\n","        .drop('wm_yr_wk')\n","\n","        .pipe(lambda df: add_ordinal_encoding(df, [\"dept_id\", \"item_id\", \"store_id\", \"state_id\", \"cat_id\"]))\n","    )\n","\n","    xtrain, xval, ytrain, yval, test, xfeats = split_train_valid_test(df, first_eval_day=first_eval_day, lags=lags, windows=windows)\n","    return xtrain, xval, ytrain, yval, test, xfeats"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oXV9koa1YONy"},"outputs":[],"source":["xtrain, xval, ytrain, yval, test, xfeats = prep_data(sales, first_eval_day=FIRST, length_eval_window=LENGTH, drop_days=DROP, lags=LAGS, windows=WINDOWS)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uw2Q6e_QYONy","outputId":"9fa392de-bee2-4d43-b24d-c8e33ac40b7d"},"outputs":[{"data":{"text/plain":["(8095095,)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jzSm6J3IYONy","outputId":"afbfc0f5-94f3-40fe-c789-adc9e72ef787"},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/yongjian.tek/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n","/Users/yongjian.tek/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n","  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"]},{"name":"stdout","output_type":"stream","text":["[LightGBM] [Warning] There are no meaningful features, as all feature values are constant.\n"]},{"name":"stderr","output_type":"stream","text":["[LightGBM] [Fatal] Length of label is not same with #data\n"]},{"ename":"LightGBMError","evalue":"Length of label is not same with #data","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[0;32mIn[59], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     lgb\u001b[39m.\u001b[39mplot_importance(fit, importance_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgain\u001b[39m\u001b[39m\"\u001b[39m, precision\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, height\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m, \u001b[39m10\u001b[39m));\n\u001b[1;32m     26\u001b[0m     \u001b[39mreturn\u001b[39;00m fit\n\u001b[0;32m---> 28\u001b[0m fit \u001b[39m=\u001b[39m fit_model(train, valid)\n","Cell \u001b[0;32mIn[59], line 17\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(train, valid)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\" Fit LightGBM model \"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m params \u001b[39m=\u001b[39m {\n\u001b[1;32m      5\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmetric\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mrmse\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m'\u001b[39m\u001b[39mpoisson\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mcolsample_bytree\u001b[39m\u001b[39m'\u001b[39m: \u001b[39m0.7\u001b[39m\n\u001b[1;32m     15\u001b[0m }\n\u001b[0;32m---> 17\u001b[0m fit \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain(params, \n\u001b[1;32m     18\u001b[0m                 train, \n\u001b[1;32m     19\u001b[0m                 num_boost_round \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, \n\u001b[1;32m     20\u001b[0m                 valid_sets \u001b[39m=\u001b[39;49m [valid], \n\u001b[1;32m     21\u001b[0m                 early_stopping_rounds \u001b[39m=\u001b[39;49m \u001b[39m200\u001b[39;49m,\n\u001b[1;32m     22\u001b[0m                 verbose_eval \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m lgb\u001b[39m.\u001b[39mplot_importance(fit, importance_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgain\u001b[39m\u001b[39m\"\u001b[39m, precision\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, height\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m6\u001b[39m, \u001b[39m10\u001b[39m));\n\u001b[1;32m     26\u001b[0m \u001b[39mreturn\u001b[39;00m fit\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39m# construct booster\u001b[39;00m\n\u001b[1;32m    270\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 271\u001b[0m     booster \u001b[39m=\u001b[39m Booster(params\u001b[39m=\u001b[39;49mparams, train_set\u001b[39m=\u001b[39;49mtrain_set)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m is_valid_contain_train:\n\u001b[1;32m    273\u001b[0m         booster\u001b[39m.\u001b[39mset_train_data_name(train_data_name)\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[0;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[1;32m   2598\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_network(\n\u001b[1;32m   2599\u001b[0m         machines\u001b[39m=\u001b[39mmachines,\n\u001b[1;32m   2600\u001b[0m         local_listen_port\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mlocal_listen_port\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[1;32m   2601\u001b[0m         listen_time_out\u001b[39m=\u001b[39mparams\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mtime_out\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m120\u001b[39m),\n\u001b[1;32m   2602\u001b[0m         num_machines\u001b[39m=\u001b[39mparams[\u001b[39m\"\u001b[39m\u001b[39mnum_machines\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   2603\u001b[0m     )\n\u001b[1;32m   2604\u001b[0m \u001b[39m# construct booster object\u001b[39;00m\n\u001b[0;32m-> 2605\u001b[0m train_set\u001b[39m.\u001b[39;49mconstruct()\n\u001b[1;32m   2606\u001b[0m \u001b[39m# copy the parameters from train_set\u001b[39;00m\n\u001b[1;32m   2607\u001b[0m params\u001b[39m.\u001b[39mupdate(train_set\u001b[39m.\u001b[39mget_params())\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1812\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_init_score_by_predictor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_predictor, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, used_indices)\n\u001b[1;32m   1813\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1814\u001b[0m     \u001b[39m# create train\u001b[39;00m\n\u001b[0;32m-> 1815\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lazy_init(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata, label\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel,\n\u001b[1;32m   1816\u001b[0m                     weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, group\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroup,\n\u001b[1;32m   1817\u001b[0m                     init_score\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit_score, predictor\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predictor,\n\u001b[1;32m   1818\u001b[0m                     silent\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msilent, feature_name\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_name,\n\u001b[1;32m   1819\u001b[0m                     categorical_feature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcategorical_feature, params\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams)\n\u001b[1;32m   1820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfree_raw_data:\n\u001b[1;32m   1821\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/basic.py:1557\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[0;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[1;32m   1555\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCannot initialize Dataset from \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(data)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1556\u001b[0m \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1557\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_label(label)\n\u001b[1;32m   1558\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_label() \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1559\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLabel should not be None\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/basic.py:2164\u001b[0m, in \u001b[0;36mDataset.set_label\u001b[0;34m(self, label)\u001b[0m\n\u001b[1;32m   2162\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2163\u001b[0m     label \u001b[39m=\u001b[39m list_to_1d_numpy(_label_from_pandas(label), name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 2164\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_field(\u001b[39m'\u001b[39;49m\u001b[39mlabel\u001b[39;49m\u001b[39m'\u001b[39;49m, label)\n\u001b[1;32m   2165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_field(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m)  \u001b[39m# original values can be modified at cpp side\u001b[39;00m\n\u001b[1;32m   2166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/basic.py:1993\u001b[0m, in \u001b[0;36mDataset.set_field\u001b[0;34m(self, field_name, data)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[39mif\u001b[39;00m type_data \u001b[39m!=\u001b[39m FIELD_TYPE_MAPPER[field_name]:\n\u001b[1;32m   1992\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput type error for set_field\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1993\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_DatasetSetField(\n\u001b[1;32m   1994\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   1995\u001b[0m     c_str(field_name),\n\u001b[1;32m   1996\u001b[0m     ptr_data,\n\u001b[1;32m   1997\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(\u001b[39mlen\u001b[39;49m(data)),\n\u001b[1;32m   1998\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(type_data)))\n\u001b[1;32m   1999\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   2000\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/m5-forecasting-accuracy/lib/python3.10/site-packages/lightgbm/basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n","\u001b[0;31mLightGBMError\u001b[0m: Length of label is not same with #data"]}],"source":["def fit_model(train: lgb.Dataset, valid: lgb.Dataset):\n","    \"\"\" Fit LightGBM model \"\"\"\n","     \n","    params = {\n","        'metric': 'rmse',\n","        'objective': 'poisson',\n","        'seed': 200,\n","        'force_row_wise' : True,\n","        'learning_rate' : 0.08,\n","        'lambda': 0.1,\n","        'num_leaves': 63,\n","        'sub_row' : 0.7,\n","        'bagging_freq' : 1,\n","        'colsample_bytree': 0.7\n","    }\n","\n","    fit = lgb.train(params, \n","                    train, \n","                    num_boost_round = 1, \n","                    valid_sets = [valid], \n","                    early_stopping_rounds = 200,\n","                    verbose_eval = 100)\n","    \n","    lgb.plot_importance(fit, importance_type=\"gain\", precision=0, height=0.5, figsize=(6, 10));\n","    \n","    return fit\n","\n","fit = fit_model(train, valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S5g_yJFCYONz"},"outputs":[],"source":["def demand_features_eval(df):\n","    \"\"\" Same as demand_features but for the step-by-step evaluation \"\"\"\n","    out = df.groupby('id', sort=False).last()\n","    for lag in LAGS:\n","        out[f'lag_t{lag}'] = df.groupby('id', sort=False)['demand'].nth(-lag-1).astype(\"float32\")\n","        for w in WINDOWS:\n","            out[f'rolling_mean_lag{lag}_w{w}'] = df.groupby('id', sort=False)['demand'].nth(list(range(-lag-w, -lag))).groupby('id', sort=False).mean().astype(\"float32\")\n","    \n","    return out.reset_index()\n","\n","def pred_all(fit, test, x):\n","    \"\"\" Calculate predictions \"\"\"\n","    \n","    # Recursive prediction\n","    for i, day in enumerate(np.arange(FIRST, FIRST + LENGTH)):\n","        test_day = demand_features_eval(test[(test.d <= day) & (test.d >= day - max(LAGS) - max(WINDOWS))])\n","        test.loc[test.d == day, \"demand\"] = fit.predict(test_day[x])\n","    \n","    return test\n","\n","pred = pred_all(fit, test, xfeats)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kv-eQu2pYONz"},"outputs":[],"source":["pred_to_csv(pred, cols=sample_submission.columns, file=\"submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Frst_FnrYONz"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3LvP5KB1YONz"},"outputs":[],"source":["\n","def pred_to_csv(test, cols=sample_submission_accuracy.columns, file=\"submission.csv\"):\n","    \"\"\" Reshape predictions and save submission csv \"\"\"\n","     \n","    # Prepare for reshaping\n","    test = test.assign(id=test.id + \"_\" + np.where(test.d < FIRST, \"validation\", \"evaluation\"),\n","                       F=\"F\" + (test.d - FIRST + LENGTH + 1 - LENGTH * (test.d >= FIRST)).astype(\"str\"))\n","    \n","    # Reshape\n","    submission = test.pivot(index=\"id\", columns=\"F\", values=\"demand\").reset_index()[cols].fillna(1)\n","    \n","    # Export\n","    submission.to_csv(file, index=False)\n","    \n","    return True\n","\n","# df = prep_data(sales, 1000 - 28)\n","# df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xllpv5cmYON0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MpQy-0ZOYON0"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nImiZSCTYON0"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"88DxOg2eYON0"},"source":["## Run the code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T77gZyANYON0"},"outputs":[],"source":["# train, valid, test, x = prep_data(sales, 1000 - 28)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"78L_7GkfYON0"},"outputs":[],"source":["# fit = fit_model(train, valid)\n","# pred = pred_all(fit, test, x)\n","# pred_to_csv(pred, cols=sample_submission.columns, file=\"submission.csv\")"]}],"metadata":{"kernelspec":{"display_name":"m5-forecasting-accuracy","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}